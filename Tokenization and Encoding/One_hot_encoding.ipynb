{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D-otXkFWfMug"
   },
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_data)\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DIzq-HGcgLqO"
   },
   "outputs": [],
   "source": [
    "# Convert text to sequences\n",
    "train_sequences = tokenizer.texts_to_sequences(train_data)\n",
    "test_sequences = tokenizer.texts_to_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7FZyeEaKgSfW"
   },
   "outputs": [],
   "source": [
    "# Padding sequences\n",
    "max_length = max([len(x) for x in train_sequences])  # Find the maximum sequence length\n",
    "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding='post')\n",
    "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ddB0VhISgmMD",
    "outputId": "af8da13d-e65d-4246-d21e-9495012d56f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample padded train sequence:\n",
      " [   1  168 3003 3986 4515 9420 3276 1671  422  555  278  113    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "# Inspect padded sequences\n",
    "print(\"Sample padded train sequence:\\n\", train_padded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qn8ihoggg9Wn",
    "outputId": "176ff7f8-bf70-4717-9311-ee7c6b943def"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample padded test sequence:\n",
      " [1724  932 8336   15  282 2252   34  216 4849    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample padded test sequence:\\n\", test_padded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "udkQP4Ezielf",
    "outputId": "89d16620-dcbe-4897-a7c2-9ce85ab14763"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of padded sequences: (22802, 106)\n"
     ]
    }
   ],
   "source": [
    "# Print dimensions of padded sequences\n",
    "print(f'shape of padded sequences: {train_padded.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FTUcqNbNjLze"
   },
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "train_one_hot = np.zeros((len(train_padded), max_length, vocab_size), dtype=np.float32)\n",
    "for i, seq in enumerate(train_padded):\n",
    "    for j, index in enumerate(seq):\n",
    "        if index != 0:  # Skip padding\n",
    "            train_one_hot[i, j, index] = 1.0\n",
    "\n",
    "test_one_hot = np.zeros((len(test_padded), max_length, vocab_size), dtype=np.float32)\n",
    "for i, seq in enumerate(test_padded):\n",
    "    for j, index in enumerate(seq):\n",
    "        if index != 0:  # Skip padding\n",
    "            test_one_hot[i, j, index] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iPv7BrC0jO9c",
    "outputId": "4bbd35ae-dcbd-4e4c-a00d-ff637d5ca4e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_one_hot: (22802, 106, 25734)\n",
      "Shape of test_one_hot: (5701, 106, 25734)\n",
      "Sample one-hot encoded train sequence:\n",
      " [[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Sample one-hot encoded test sequence:\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Inspect one-hot encoded sequences\n",
    "print(\"Shape of train_one_hot:\", train_one_hot.shape)  #Prints the shape of the one-hot encoded training set to verify the dimensions.\n",
    "print(\"Shape of test_one_hot:\", test_one_hot.shape)    #Prints the shape of the one-hot encoded test set to verify the dimensions.\n",
    "print(\"Sample one-hot encoded train sequence:\\n\", train_one_hot[0])     #Prints the first one-hot encoded sequence in the training set.\n",
    "print(\"Sample one-hot encoded test sequence:\\n\", test_one_hot[0])       #Prints the first one-hot encoded sequence in the test set.\n",
    "\n",
    "#The first dimension corresponds to the number of sequences.\n",
    "#The second dimension corresponds to the positions within each sequence (up to max_length).\n",
    "#The third dimension corresponds to the vocabulary, with each position in the sequence having a one-hot encoded vector representing the word at that position.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
